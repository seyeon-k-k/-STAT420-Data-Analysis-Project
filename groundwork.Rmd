---
title: "Data Analysis Project Proposal"
output: html_document
date: "2024-11-28"
---

## Title: The Science of Wine: Predicting Quality from Chemical Properties

### 1. Complete the dataset

We combine "winequality-white.csv" and "winequality-red.csv" and add a new variable, `color` which represents 1 for red wine and 0 for white wine.

```{r}

wine_data_white = read.csv("winequality-white.csv", sep=";")

# Add the "color" variable for white wine (0 = white wine)
wine_data_white$color = 0

wine_data_red = read.csv("winequality-red.csv", sep=";")

# Add the "color" variable for red wine (1 = red wine)
wine_data_red$color = 1

# Combine the two datasets
wine_data_combined = rbind(wine_data_white, wine_data_red)

# Make sure the "quality" variable is numeric
wine_data_combined$quality <- as.numeric(wine_data_combined$quality)

str(wine_data_combined)

```

When it comes to "quality" variable that we are using as the target variable, we use the variable as numeric, assuming that the difference between a quality of 6 and 7 is the same as the difference between a quality of 7 and 8 and allowing to make predictions for any quality.

#### 1.2 Check For missing data

```{r}
# Check if there is any missing data in the dataset
anyNA(wine_data_combined)  # Returns TRUE if there are missing values

# Summarize missing values per column
colSums(is.na(wine_data_combined))

```

### 2. Look into Colinearity

When we look into the collinearity among variables, there seems no big collinearitys.

```{r, message = FALSE, warning = FALSE}

library(faraway)
pairs(wine_data_combined, col = "darkorange")

```

```{r}

round(cor(wine_data_combined), 2)

```

Visualize Correlation Matrix with Heatmap
```{r}
library(corrplot)
cor_matrix <- cor(wine_data_combined[, sapply(wine_data_combined, is.numeric)])
corrplot(cor_matrix, method = "color", tl.col = "black", tl.srt = 45)

```

1. Correlations with the Target Variable (Qaulity)
1.1 Strongest Correlation: alcohol
  - The Correlation of 0.44 is moderately positive.
  - It indicates that higher alcohol content is asscoviated with higher wine quality; thus, alcohole is likely a strong predictor
1.2 Weak Correlations:
  - `Sulphates`, `citric.acid`, and `free.sulfur.dioxide` have a weak or negligible correlation with `quality`.
  - These may not significantly contribute to predicting wine quality unless interacions are involved.
1.3 Negative Correlations:
  - `volatile.acidity` with $r=-0.27$ indicates that a higher valatile acidity (associated with wine spoilage) lowers the overall quality.
  - `density` with  $r=-0.31$ shows that the higher density correlates with lower quality. Improper fermantation or excessive sugar contents could possily plays a role here.

2. Multicollinearity Between Predictors
2.1 Higher Correlated Predictors
  - `total.sulfur.dioxide` and `free.sulfur.dioxide` have a high corraltion with $r=0.72$. We can consider using one or combining them.
  - `volatile.acidity` and `color` with $r=0.65$ also have significant correlation. Red wine (`color = 1`) might tend to have higher volatile acidity.
2.2 Some Correlations
  - `fixed.acidity` and `density` with $r=0.46$ are positively correlated, likely because higher acidity contributes to higher density.
  - `color` and `chlorides` with $r=0.51$. Red wine appears to have higher chloride levels on average.
  
3 Little Correlation
  - `pH` and `Sulphates` show minimal correlation with `quality`, $r=0.02$ and $r=0.04$ respectively. 
  


#### 2.2 Testing baseline model based on Correlations
Assuming that the correlations exist, the predictors are `alcohol`, `volatile.acidity`, `density`, and `color`.

```{r}
lm_baseline <- lm(quality ~ alcohol + volatile.acidity + density + color, data = wine_data_combined)
summary(lm_baseline)

```

**Predictor Coefficients:**
  - `Alcohol` (0.36874) is highly significant the $p < 2.2*10^{-16}$.
  With each unit increase in alcohol content, wine quality increases by 0.368 points, holding other predictors constant.
  - `volatile.acidity`(-1.678659) is highly significant the $p < 2.2*10^{-16}$.
  For each unit increases in volatile acidity, wine quality decreases by 1.677 points, holdinh other predictors constant. 
  - `density` (29.29930), for each unit increase in denstiy, wine quality increase by 29.3 points, but this is less intuitive and required futher investigation.
  - `color` (0.13504) is significant with $p = 2.58*10^{-5}$
  
**Model Summary**
 Residual Standard Error of 0.7467 incicates that the average deviation of the observed quality socres from the predicted values.
 Multiple R-Squared of 0.2693 shows that only around 27% of the variation in quality is explained by this model.
 Adjusted R-Square of 0.2689 shows that the model is not overfitting but is limited in explainin variability.
 F-Statistic of 598.2 indicate that at least one predictor is strongly associated with the response as the model is highly significant $p = 2.2*10^{-16}$.
 
**Test for Significance of Density Predictor** Use ANOVA to check if it makes a significant difference

```{r}
model_wo_density <- lm(quality ~ alcohol + volatile.acidity + color, data = wine_data_combined)

anova(lm_baseline, model_wo_density)
```
A p-value of 2.938e-09 is significant, indicating that the difference resulting from removing the density predictor is significant. Therefore, the model is better off with density included than not.

**Test For Multicollinearity:** Use VIF to confirm the Multicollinearity

```{r}
library(car)
vif(lm_baseline)

```

VIF Scores:
 - All predictors have VIF < 5 showing no serious multicollonearity issues; thus, no predictors need to be removed based on the VIF.  

Now, we will experiment with models using different interaction terms of the four non-collinear variables shown above (alcohol, color, density, and volatile.acidity) to see what would be an optimal model. 
```{r}
model2 <- lm(quality ~ (alcohol + volatile.acidity + density + color)^2, data = wine_data_combined)

summary(model2)
```

```{r}
model3 <- lm(quality ~ (alcohol + volatile.acidity + density + color)^3, data = wine_data_combined)

summary(model2)
```

```{r}
model4 <- lm(quality ~ (alcohol + volatile.acidity + density + color)^4, data = wine_data_combined)

summary(model4)
```

Looking at the revised models including only the significant terms from the 2, 3, and 4 way interaction models, and comparing them to the baseline model, gives us this:

```{r}
model_red2 <- lm(
  quality ~ alcohol + density + alcohol:volatile.acidity + alcohol:density + volatile.acidity:color,
  data = wine_data_combined
)

model_red3 <- lm(
  quality ~ alcohol + density + alcohol:volatile.acidity:color,
  data = wine_data_combined
)
```

```{r}
bic_values <- data.frame(
  Model = c("lm_baseline", "model_red2", "model_red3", "model4"),
  BIC = c(BIC(lm_baseline), BIC(model_red2), BIC(model_red3), BIC(model4))
)

print(bic_values)
```

The 4 way interaction model has the smallest BIC value, despite it being the most complex.
<br><br>
Now, let's run a  bi-directional step function to find what R thinks is the optimal model. Then, we will compare this to the best of the models from above, which is the 4 way interaction model.

```{r}
max_model <- lm(quality ~ (alcohol + volatile.acidity + density + color)^4, data = wine_data_combined)

null_model <- lm(quality ~ 1, data = wine_data_combined)

step_model <- step(lm_baseline, scope = list(lower = null_model, upper = max_model), direction = "both", trace = 1)

summary(step_model)
```

**Conduct Checks on the Stepwise Model**

```{r}
plot(step_model)
```

```{r}
vif(step_model, type = 'predictor')
```

```{r}
BIC(step_model)
```

```{r}
library(caret)

step_formula <- formula(step_model)

train_ctrl <- trainControl(method = "cv", number = 10)

cv_model <- train(step_formula, 
                  data = wine_data_combined, 
                  method = "lm",        
                  trControl = train_ctrl) 

print(cv_model)

cv_model$results
```

This stepwise model seems to perform better than or about the same as the 4 way interaction model in each statistic, so using the predictors alcohol, density, color, and volatile.acidity, this will be the preferred model to use. 

### 3. Build Additive Multi Linear Regression Model

We first build additive MLR model for ground work and we find that the model has low adjusted R squared and high cross-validated RMSE, we can't say this is a good model.

```{r}
additive_model = lm(quality ~ ., data = wine_data_combined)

# Adjusted R Sqaured 
additive_model_adjR2 = summary(additive_model)$adj.r.squared
additive_model_adjR2
# Cross-Validated RMSE 
additive_model_CVRMSE = sqrt(mean((resid(additive_model) / (1 - hatvalues(additive_model))) ^ 2))
additive_model_CVRMSE

```
Here, let's take a look at influential points.

```{r, message = FALSE, warning = FALSE}

sum(cooks.distance(additive_model) > 4 / length(cooks.distance(additive_model)))

```
Here we find 317 influential points in our dataset and remove them which actually works!!

```{r, message = FALSE, warning = FALSE}

cd = cooks.distance(additive_model)

additive_model_fix = lm(quality ~ ., data = wine_data_combined, subset = cd < 4 / length(cd))

# Adjusted R Sqaured 
additive_model_adjR2 = summary(additive_model_fix)$adj.r.squared
additive_model_adjR2
# Cross-Validated RMSE 
additive_model_CVRMSE = sqrt(mean((resid(additive_model_fix) / (1 - hatvalues(additive_model_fix))) ^ 2))
additive_model_CVRMSE

```

Here we try two-way interaction model and three-way interaction model and two-way interaction model with quadratic terms as well. We can observe the adjusted R Sqaured and cross-validated RMSE get bigger as the model gets bigger.

```{r}

interaction2_model = lm(quality ~ .^2, data = wine_data_combined)

cd = cooks.distance(interaction2_model)

interaction2_model_fix = lm(quality ~ .^2, data = wine_data_combined, subset = cd < 4 / length(cd))

# Adjusted R Sqaured 
interaction2_model_adjR2 = summary(interaction2_model_fix)$adj.r.squared
interaction2_model_adjR2
# Cross-Validated RMSE 
interaction2_model_CVRMSE = sqrt(mean((resid(interaction2_model_fix) / (1 - hatvalues(interaction2_model_fix))) ^ 2))
interaction2_model_CVRMSE

```

```{r}

interaction3_model = lm(quality ~ .^3, data = wine_data_combined)

cd = cooks.distance(interaction3_model)

interaction3_model_fix = lm(quality ~ .^3, data = wine_data_combined, subset = cd < 4 / length(cd))

# Adjusted R Sqaured 
interaction3_model_adjR2 = summary(interaction3_model_fix)$adj.r.squared
interaction3_model_adjR2
# Cross-Validated RMSE 
interaction3_model_CVRMSE = sqrt(mean((resid(interaction3_model_fix) / (1 - hatvalues(interaction3_model_fix))) ^ 2))
interaction3_model_CVRMSE
```
```{r}

poly_model = lm(quality ~ .^2 + I(fixed.acidity^2) + I(volatile.acidity^2) + I(citric.acid^2) + I(residual.sugar^2) + I(chlorides^2) + I(free.sulfur.dioxide^2) + I(total.sulfur.dioxide^2) + I(density^2) + I(pH^2) + I(alcohol^2) + I(color^2), data = wine_data_combined)

cd = cooks.distance(poly_model)

poly_model_fix = lm(quality ~ .^2 + I(fixed.acidity^2) + I(volatile.acidity^2) + I(citric.acid^2) + I(residual.sugar^2) + I(chlorides^2) + I(free.sulfur.dioxide^2) + I(total.sulfur.dioxide^2) + I(density^2) + I(pH^2) + I(alcohol^2) + I(color^2), data = wine_data_combined, subset = cd < 4 / length(cd))

# Adjusted R Sqaured 
poly_model_adjR2 = summary(poly_model_fix)$adj.r.squared
poly_model_adjR2
# Cross-Validated RMSE 
poly_model_CVRMSE = sqrt(mean((resid(poly_model_fix) / (1 - hatvalues(poly_model_fix))) ^ 2))
poly_model_CVRMSE

```

### 4. Make The Response Logged

We just give it a shot on logging the responsem and the result is.... terrible.

```{r}

response_log_model = lm(log(quality) ~ ., data = wine_data_combined)

cd = cooks.distance(response_log_model)

response_log_model_fix = lm(log(quality) ~ ., data = wine_data_combined, subset = cd < 4 / length(cd))

# Adjusted R Sqaured 
response_log_model_adjR2 = summary(response_log_model_fix)$adj.r.squared
response_log_model_adjR2
# Cross-Validated RMSE 
response_log_model_CVRMSE = sqrt(mean((resid(response_log_model_fix) / (1 - hatvalues(response_log_model_fix))) ^ 2))
response_log_model_CVRMSE
```

### 5. Make Some Predictors Logged

```{r}

log_model = lm(quality ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + log(free.sulfur.dioxide) + log(total.sulfur.dioxide) + density + pH + sulphates + alcohol + color, data = wine_data_combined)

cd = cooks.distance(log_model)

log_model_fix = lm(quality ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + log(free.sulfur.dioxide) + log(total.sulfur.dioxide) + density + pH + sulphates + alcohol + color, data = wine_data_combined, subset = cd < 4 / length(cd))
  
# Adjusted R Sqaured 
log_model_adjR2 = summary(log_model_fix)$adj.r.squared
log_model_adjR2
# Cross-Validated RMSE 
log_model_CVRMSE = sqrt(mean((resid(log_model_fix) / (1 - hatvalues(log_model_fix))) ^ 2))
log_model_CVRMSE


```
### 6. Try Box-Cox Transformation On The Response Variable

We shortly introduced Box-Cox Transformation in the class, but here we are going to try applying it referring to the  textbook. 

```{r}

library(MASS)

model = lm(quality ~ ., data = wine_data_combined)
cd = cooks.distance(model)

bc = boxcox(lm(quality ~ ., data = wine_data_combined, subset = cd < 4 / length(cd)))
lambda = bc$x[which.max(bc$y)]
quality_bc = (wine_data_combined$quality^lambda - 1) / lambda
boxcox_model = lm(quality_bc ~ ., data = wine_data_combined)

# Adjusted R Sqaured 
boxcox_model_adjR2 = summary(boxcox_model)$adj.r.squared
boxcox_model_adjR2
# Cross-Validated RMSE 
boxcox_model_CVRMSE = sqrt(mean((resid(boxcox_model) / (1 - hatvalues(boxcox_model))) ^ 2))
boxcox_model_CVRMSE


```

### 7. Backward Model Selection

Here we first try backward selection procedure with the two-way interaction model. Then, we do backward selection procedure with the two-way interaction model again, but this time we apply Box-Cox Transformation on it. (We are supposed to try three-way interaction model as it has better performance, but it takes too long to get the model from backward selection)

```{r}
# Backward selection procedure with the two-way interaction model
backwardBIC_model = step(interaction2_model, direction = "backward", k = log(length(resid(interaction2_model))), trace = 0, na.action = na.omit)

backwardBIC_model_adjR2 = summary(backwardBIC_model)$adj.r.squared
backwardBIC_model_adjR2
# Cross-Validated RMSE 
backwardBIC_model_CVRMSE = sqrt(mean((resid(backwardBIC_model) / (1 - hatvalues(backwardBIC_model))) ^ 2))
backwardBIC_model_CVRMSE

# Backward selection procedure with the two-way interaction model with Box-Cox Transformation

bc = boxcox(lm(quality ~ (.- color)^2, data = wine_data_combined))
lambda = bc$x[which.max(bc$y)]
quality_bc = (wine_data_combined$quality^lambda - 1) / lambda
boxcox_bigmodel = lm(quality_bc ~ (.- color)^2, data = wine_data_combined)

# Adjusted R Sqaured 
boxcox_bigmodel_adjR2 = summary(boxcox_model)$adj.r.squared
boxcox_bigmodel_adjR2
# Cross-Validated RMSE 
boxcox_bigmodel_CVRMSE = sqrt(mean((resid(boxcox_model) / (1 - hatvalues(boxcox_model))) ^ 2))
boxcox_bigmodel_CVRMSE

backwardBIC_bcmodel = step(boxcox_bigmodel, direction = "backward", k = log(length(resid(boxcox_bigmodel))), trace = 0)

# Adjusted R Sqaured 
backwardBIC_bcmodel_adjR2 = summary(backwardBIC_model)$adj.r.squared
backwardBIC_bcmodel_adjR2
# Cross-Validated RMSE 
backwardBIC_bcmodel_CVRMSE = sqrt(mean((resid(backwardBIC_bcmodel) / (1 - hatvalues(backwardBIC_bcmodel))) ^ 2))
backwardBIC_bcmodel_CVRMSE

```

### 8. Choose the best model

```{r}

comparison_table1 =  data.frame(
  Model = c("Additive Model", "Two-Way Interaction Model", "Three-Way Interaction Model", "Quadractic Model"),
  Adjusted_R2 = c(additive_model_adjR2, interaction2_model_adjR2, interaction3_model_adjR2, poly_model_adjR2),
  CVRMSE = c(additive_model_CVRMSE, interaction2_model_CVRMSE, interaction3_model_CVRMSE, poly_model_CVRMSE)
)

print(comparison_table1)

comparison_table2 =  data.frame(
  Model = c("Logged Response Model", "Logged Predictors Model", "Box-Cox Model"),
  Adjusted_R2 = c(response_log_model_adjR2, log_model_adjR2, boxcox_model_adjR2),
  CVRMSE = c(response_log_model_CVRMSE, log_model_CVRMSE, boxcox_model_CVRMSE)
)

print(comparison_table2)

comparison_table3 =  data.frame(
  Model = c("Backward Selection From Two-Way Interaction Model", "Backward Selection From Two-Way Interaction Model (Box-Cox)"),
  Adjusted_R2 = c(backwardBIC_model_adjR2, backwardBIC_bcmodel_adjR2),
  CVRMSE = c(backwardBIC_model_CVRMSE, backwardBIC_bcmodel_CVRMSE)
)

print(comparison_table3)

```




### 9. Diagnose The Chosen Model 

```{r}


plot(fitted(interaction3_model_fix), resid(interaction3_model_fix), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Residuals Plot")
abline(h = 0, col = "darkorange", lwd = 2)

plot(fitted(backwardBIC_bcmodel), resid(backwardBIC_bcmodel), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Residuals Plot")
abline(h = 0, col = "darkorange", lwd = 2)


```
Here we can see the issue with the structure of our data. Since our response variable "quality" is discrete, we are facing problems with the residuals because the MLR model assumes continuous data and seeing violations of homoscedasticity and linearity assumption.

Here we do Breusch-Pagan Test and Shapiro-Wilk Test for formal testing and find very small p-values for both tests as we expected.


```{r, message = FALSE, warning = FALSE}

library(lmtest)

bptest(interaction3_model_fix)


# We cannot use shapiro.test as the sample size is over 5000
# shapiro.test(resid(backwardBIC_model2))

# Therefore here we use Anderson-Darling test that doesn't have the same sample size restrictions

library(nortest)
ad.test(resid(interaction3_model_fix))

bptest(backwardBIC_bcmodel)
ad.test(resid(backwardBIC_bcmodel))

```
